# Paper Reading List

## Recommendation
* 2/20 2023  [Large Scale Product Graph Construction for Recommendation in E-commerce](https://arxiv.org/pdf/2010.05525.pdf) [***Swingi2i***]
* 1/10 2023  [DRN- A Deep Reinforcement Learning Framework for News Recommendation](https://github.com/wzhe06/Reco-papers/blob/master/Reinforcement%20Learning%20in%20Reco/DRN-%20A%20Deep%20Reinforcement%20Learning%20Framework%20for%20News%20Recommendation%20\(MSRA%202018\).pdf) [***RL***] 
* 10/02 2022 [Values of User Exploration in Recommender Systems](https://dl.acm.org/doi/pdf/10.1145/3460231.3474236) [***Exploration***]
* 04/18 2022 [A Contextual-Bandit Approach to Personalized News Article Recommendation](https://arxiv.org/pdf/1003.0146.pdf) [***LinUCB***]
* 04/11 2022 [Show Me the Whole World: Towards Entire Item Space Exploration for Interactive Personalized Recommendations](https://arxiv.org/pdf/1003.0146.pdf) [***MAB***]
## NLP
* 2/27 2023 [Scaling Instruction-Finetuned Language Models](https://arxiv.org/pdf/2210.11416.pdf)
* 2/14 2023 [Mengzi: Towards Lightweight yet Ingenious Pre-trained Models for Chinese](https://arxiv.org/pdf/2110.06696.pdf) [***T5***]
* 01/08 2023 [Training language models to follow instructions with human feedback](https://arxiv.org/pdf/2203.02155.pdf) [**GPT**]
* 04/05 2022 [Adversarial NLI: A New Benchmark for Natural Language Understanding](https://arxiv.org/pdf/1910.14599.pdf) [***NLP***, ***ANLI***]
    * HI + AI pipeline
* 04/03 2022 [Evaluating the Factual Consistency of Abstractive Text Summarization](https://arxiv.org/pdf/1910.12840.pdf) [***NLG***, ***consistency***]
* 04/02 2022 [SUMMAC: Re-Visiting NLI-based Models for Inconsistency Detection in Summarization](https://arxiv.org/pdf/2111.09525.pdf) [***NLG***, ***fact error***, ***hallucinations***, ***inconsistency***]
* 03/27 2022 [Survey of Hallucination in Natural Language Generation](https://arxiv.org/pdf/2202.03629.pdf) [***NLG***]
* 03/27 2022 [Multi-Fact Correction in Abstractive Text Summarization](https://arxiv.org/pdf/2010.02443.pdf) [***NLG***, ***fact error***]


